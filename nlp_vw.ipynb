{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_vw.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmAicrGIEmkYkVHHso4m9r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bavalpreet/NLP/blob/master/nlp_vw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WUbIahjbkC1",
        "colab_type": "code",
        "outputId": "d7ada8d2-37ff-4d83-dd0c-b2a4643abd86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erLN6WRZcChK",
        "colab_type": "code",
        "outputId": "50a95e14-421c-42d6-c0ce-21c23c0863c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('nps_chat')\n",
        "posts = nltk.corpus.nps_chat.xml_posts()[:20000]\n",
        "print(posts)\n",
        "\n",
        "\n",
        "def dialogue_act_features(post):\n",
        "    features = {}\n",
        "    for word in nltk.word_tokenize(post):\n",
        "        features['contains({})'.format(word.lower())] = True\n",
        "    return features\n",
        "\n",
        "featuresets = [(dialogue_act_features(post.text), post.get('class')) for post in posts]\n",
        "size = int(len(featuresets) * 0.1)\n",
        "train_set, test_set = featuresets[size:], featuresets[:size]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Package nps_chat is already up-to-date!\n",
            "[<Element 'Post' at 0x7f3122c08458>, <Element 'Post' at 0x7f3122c08d18>, ...]\n",
            "0.6685606060606061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I9BKtDLqN_m",
        "colab_type": "code",
        "outputId": "2ae7b058-e266-4c45-b268-96ca118cc8d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "from nltk.corpus import nps_chat\n",
        "import pandas as pd\n",
        "data = []\n",
        "for p in nps_chat.xml_posts():\n",
        "    data.append({\"class\":p.get(\"class\"), \"text\": p.text})\n",
        "df = pd.DataFrame.from_dict(data)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Statement</td>\n",
              "      <td>now im left with this gay name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Emotion</td>\n",
              "      <td>:P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>System</td>\n",
              "      <td>PART</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Greet</td>\n",
              "      <td>hey everyone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Statement</td>\n",
              "      <td>ah well</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10562</th>\n",
              "      <td>Greet</td>\n",
              "      <td>hi 11-09-teensUser3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10563</th>\n",
              "      <td>System</td>\n",
              "      <td>JOIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10564</th>\n",
              "      <td>Greet</td>\n",
              "      <td>Hi, 11-09-teensUser197.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10565</th>\n",
              "      <td>nAnswer</td>\n",
              "      <td>Not that I know of, 11-09-teensUser98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10566</th>\n",
              "      <td>Statement</td>\n",
              "      <td>Uh.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10567 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           class                                   text\n",
              "0      Statement         now im left with this gay name\n",
              "1        Emotion                                     :P\n",
              "2         System                                   PART\n",
              "3          Greet                         hey everyone  \n",
              "4      Statement                                ah well\n",
              "...          ...                                    ...\n",
              "10562      Greet                    hi 11-09-teensUser3\n",
              "10563     System                                   JOIN\n",
              "10564      Greet                Hi, 11-09-teensUser197.\n",
              "10565    nAnswer  Not that I know of, 11-09-teensUser98\n",
              "10566  Statement                                    Uh.\n",
              "\n",
              "[10567 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ExHgLD8ErdR",
        "colab_type": "code",
        "outputId": "2bda990e-2bc1-4b7e-a56c-fbca21948ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# for vw i left runing here continue from 11-05-20\n",
        "df[\"class\"].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Statement', 'Emotion', 'System', 'Greet', 'Accept', 'Reject',\n",
              "       'whQuestion', 'Continuer', 'ynQuestion', 'yAnswer', 'Bye',\n",
              "       'Clarify', 'Emphasis', 'nAnswer', 'Other'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYEmm2S_Mi4a",
        "colab_type": "code",
        "outputId": "44cf646f-f8b8-49ec-a885-a2861e45dd3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "!apt-get install libboost-program-options-dev zlib1g-dev libboost-python-dev vowpal-wabbit"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libboost-program-options-dev is already the newest version (1.65.1.0ubuntu1).\n",
            "libboost-program-options-dev set to manually installed.\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\n",
            "zlib1g-dev set to manually installed.\n",
            "libboost-python-dev is already the newest version (1.65.1.0ubuntu1).\n",
            "libboost-python-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  libvw0\n",
            "Suggested packages:\n",
            "  vowpal-wabbit-doc\n",
            "The following NEW packages will be installed:\n",
            "  libvw0 vowpal-wabbit\n",
            "0 upgraded, 2 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 797 kB of archives.\n",
            "After this operation, 3,034 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libvw0 amd64 8.5.0.dfsg1-1 [748 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 vowpal-wabbit amd64 8.5.0.dfsg1-1 [49.1 kB]\n",
            "Fetched 797 kB in 1s (982 kB/s)\n",
            "Selecting previously unselected package libvw0.\n",
            "(Reading database ... 144429 files and directories currently installed.)\n",
            "Preparing to unpack .../libvw0_8.5.0.dfsg1-1_amd64.deb ...\n",
            "Unpacking libvw0 (8.5.0.dfsg1-1) ...\n",
            "Selecting previously unselected package vowpal-wabbit.\n",
            "Preparing to unpack .../vowpal-wabbit_8.5.0.dfsg1-1_amd64.deb ...\n",
            "Unpacking vowpal-wabbit (8.5.0.dfsg1-1) ...\n",
            "Setting up libvw0 (8.5.0.dfsg1-1) ...\n",
            "Setting up vowpal-wabbit (8.5.0.dfsg1-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXDutscfy_MM",
        "colab_type": "code",
        "outputId": "3987d381-65dd-4beb-d3bb-f48d42c06dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!vw --help"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num weight bits = 18\n",
            "learning rate = 0.5\n",
            "initial_t = 0\n",
            "power_t = 0.5\n",
            "using no cache\n",
            "Reading datafile = \n",
            "num sources = 1\n",
            "\n",
            "\n",
            "VW options:\n",
            "  --random_seed arg                     seed random number generator\n",
            "  --ring_size arg                       size of example ring\n",
            "\n",
            "Update options:\n",
            "  -l [ --learning_rate ] arg            Set learning rate\n",
            "  --power_t arg                         t power value\n",
            "  --decay_learning_rate arg             Set Decay factor for learning_rate \n",
            "                                        between passes\n",
            "  --initial_t arg                       initial t value\n",
            "  --feature_mask arg                    Use existing regressor to determine \n",
            "                                        which parameters may be updated.  If no\n",
            "                                        initial_regressor given, also used for \n",
            "                                        initial weights.\n",
            "\n",
            "Weight options:\n",
            "  -i [ --initial_regressor ] arg        Initial regressor(s)\n",
            "  --initial_weight arg                  Set all weights to an initial value of \n",
            "                                        arg.\n",
            "  --random_weights arg                  make initial weights random\n",
            "  --normal_weights arg                  make initial weights normal\n",
            "  --truncated_normal_weights arg        make initial weights truncated normal\n",
            "  --sparse_weights                      Use a sparse datastructure for weights\n",
            "  --input_feature_regularizer arg       Per feature regularization input file\n",
            "\n",
            "Parallelization options:\n",
            "  --span_server arg                     Location of server for setting up \n",
            "                                        spanning tree\n",
            "  --threads                             Enable multi-threading\n",
            "  --unique_id arg (=0)                  unique id used for cluster parallel \n",
            "                                        jobs\n",
            "  --total arg (=1)                      total number of nodes used in cluster \n",
            "                                        parallel job\n",
            "  --node arg (=0)                       node number in cluster parallel job\n",
            "\n",
            "Diagnostic options:\n",
            "  --version                             Version information\n",
            "  -a [ --audit ]                        print weights of features\n",
            "  -P [ --progress ] arg                 Progress update frequency. int: \n",
            "                                        additive, float: multiplicative\n",
            "  --quiet                               Don't output disgnostics and progress \n",
            "                                        updates\n",
            "  -h [ --help ]                         Look here: http://hunch.net/~vw/ and \n",
            "                                        click on Tutorial.\n",
            "\n",
            "Feature options:\n",
            "  --hash arg                            how to hash the features. Available \n",
            "                                        options: strings, all\n",
            "  --ignore arg                          ignore namespaces beginning with \n",
            "                                        character <arg>\n",
            "  --ignore_linear arg                   ignore namespaces beginning with \n",
            "                                        character <arg> for linear terms only\n",
            "  --keep arg                            keep namespaces beginning with \n",
            "                                        character <arg>\n",
            "  --redefine arg                        redefine namespaces beginning with \n",
            "                                        characters of string S as namespace N. \n",
            "                                        <arg> shall be in form 'N:=S' where := \n",
            "                                        is operator. Empty N or S are treated \n",
            "                                        as default namespace. Use ':' as a \n",
            "                                        wildcard in S.\n",
            "  -b [ --bit_precision ] arg            number of bits in the feature table\n",
            "  --noconstant                          Don't add a constant feature\n",
            "  -C [ --constant ] arg                 Set initial value of constant\n",
            "  --ngram arg                           Generate N grams. To generate N grams \n",
            "                                        for a single namespace 'foo', arg \n",
            "                                        should be fN.\n",
            "  --skips arg                           Generate skips in N grams. This in \n",
            "                                        conjunction with the ngram tag can be \n",
            "                                        used to generate generalized \n",
            "                                        n-skip-k-gram. To generate n-skips for \n",
            "                                        a single namespace 'foo', arg should be\n",
            "                                        fN.\n",
            "  --feature_limit arg                   limit to N features. To apply to a \n",
            "                                        single namespace 'foo', arg should be \n",
            "                                        fN\n",
            "  --affix arg                           generate prefixes/suffixes of features;\n",
            "                                        argument '+2a,-3b,+1' means generate \n",
            "                                        2-char prefixes for namespace a, 3-char\n",
            "                                        suffixes for b and 1 char prefixes for \n",
            "                                        default namespace\n",
            "  --spelling arg                        compute spelling features for a give \n",
            "                                        namespace (use '_' for default \n",
            "                                        namespace)\n",
            "  --dictionary arg                      read a dictionary for additional \n",
            "                                        features (arg either 'x:file' or just \n",
            "                                        'file')\n",
            "  --dictionary_path arg                 look in this directory for \n",
            "                                        dictionaries; defaults to current \n",
            "                                        directory or env{PATH}\n",
            "  --interactions arg                    Create feature interactions of any \n",
            "                                        level between namespaces.\n",
            "  --permutations                        Use permutations instead of \n",
            "                                        combinations for feature interactions \n",
            "                                        of same namespace.\n",
            "  --leave_duplicate_interactions        Don't remove interactions with \n",
            "                                        duplicate combinations of namespaces. \n",
            "                                        For ex. this is a duplicate: '-q ab -q \n",
            "                                        ba' and a lot more in '-q ::'.\n",
            "  -q [ --quadratic ] arg                Create and use quadratic features\n",
            "  --q: arg                              : corresponds to a wildcard for all \n",
            "                                        printable characters\n",
            "  --cubic arg                           Create and use cubic features\n",
            "\n",
            "Example options:\n",
            "  -t [ --testonly ]                     Ignore label information and just test\n",
            "  --holdout_off                         no holdout data in multiple passes\n",
            "  --holdout_period arg                  holdout period for test only, default \n",
            "                                        10\n",
            "  --holdout_after arg                   holdout after n training examples, \n",
            "                                        default off (disables holdout_period)\n",
            "  --early_terminate arg                 Specify the number of passes tolerated \n",
            "                                        when holdout loss doesn't decrease \n",
            "                                        before early termination, default is 3\n",
            "  --passes arg                          Number of Training Passes\n",
            "  --initial_pass_length arg             initial number of examples per pass\n",
            "  --examples arg                        number of examples to parse\n",
            "  --min_prediction arg                  Smallest prediction to output\n",
            "  --max_prediction arg                  Largest prediction to output\n",
            "  --sort_features                       turn this on to disregard order in \n",
            "                                        which features have been defined. This \n",
            "                                        will lead to smaller cache sizes\n",
            "  --loss_function arg (=squared)        Specify the loss function to be used, \n",
            "                                        uses squared by default. Currently \n",
            "                                        available ones are squared, classic, \n",
            "                                        hinge, logistic, quantile and poisson.\n",
            "  --quantile_tau arg (=0.5)             Parameter \\tau associated with Quantile\n",
            "                                        loss. Defaults to 0.5\n",
            "  --l1 arg                              l_1 lambda\n",
            "  --l2 arg                              l_2 lambda\n",
            "  --no_bias_regularization arg          no bias in regularization\n",
            "  --named_labels arg                    use names for labels (multiclass, etc.)\n",
            "                                        rather than integers, argument \n",
            "                                        specified all possible labels, \n",
            "                                        comma-sep, eg \"--named_labels \n",
            "                                        Noun,Verb,Adj,Punc\"\n",
            "\n",
            "Output model:\n",
            "  -f [ --final_regressor ] arg          Final regressor\n",
            "  --readable_model arg                  Output human-readable final regressor \n",
            "                                        with numeric features\n",
            "  --invert_hash arg                     Output human-readable final regressor \n",
            "                                        with feature names.  Computationally \n",
            "                                        expensive.\n",
            "  --save_resume                         save extra state so learning can be \n",
            "                                        resumed later with new data\n",
            "  --preserve_performance_counters       reset performance counters when \n",
            "                                        warmstarting\n",
            "  --save_per_pass                       Save the model after every pass over \n",
            "                                        data\n",
            "  --output_feature_regularizer_binary arg\n",
            "                                        Per feature regularization output file\n",
            "  --output_feature_regularizer_text arg Per feature regularization output file,\n",
            "                                        in text\n",
            "  --id arg                              User supplied ID embedded into the \n",
            "                                        final regressor\n",
            "\n",
            "Output options:\n",
            "  -p [ --predictions ] arg              File to output predictions to\n",
            "  -r [ --raw_predictions ] arg          File to output unnormalized predictions\n",
            "                                        to\n",
            "\n",
            "Reduction options, use [option] --help for more info:\n",
            "\n",
            "  --audit_regressor arg                 stores feature names and their \n",
            "                                        regressor values. Same dataset must be \n",
            "                                        used for both regressor training and \n",
            "                                        this mode.\n",
            "\n",
            "  --search arg                          Use learning to search, \n",
            "                                        argument=maximum action id or 0 for LDF\n",
            "\n",
            "  --replay_c arg                        use experience replay at a specified \n",
            "                                        level [b=classification/regression, \n",
            "                                        m=multiclass, c=cost sensitive] with \n",
            "                                        specified buffer size\n",
            "\n",
            "  --explore_eval                        Evaluate explore_eval adf policies\n",
            "\n",
            "  --cbify arg                           Convert multiclass on <k> classes into \n",
            "                                        a contextual bandit problem\n",
            "\n",
            "  --cb_explore_adf                      Online explore-exploit for a contextual\n",
            "                                        bandit problem with multiline action \n",
            "                                        dependent features\n",
            "\n",
            "  --cb_explore arg                      Online explore-exploit for a <k> action\n",
            "                                        contextual bandit problem\n",
            "\n",
            "  --multiworld_test arg                 Evaluate features as a policies\n",
            "\n",
            "  --cb_adf                              Do Contextual Bandit learning with \n",
            "                                        multiline action dependent features.\n",
            "\n",
            "  --cb arg                              Use contextual bandit learning with <k>\n",
            "                                        costs\n",
            "\n",
            "  --csoaa_ldf arg                       Use one-against-all multiclass learning\n",
            "                                        with label dependent features.  Specify\n",
            "                                        singleline or multiline.\n",
            "\n",
            "  --wap_ldf arg                         Use weighted all-pairs multiclass \n",
            "                                        learning with label dependent features.\n",
            "                                          Specify singleline or multiline.\n",
            "\n",
            "  --interact arg                        Put weights on feature products from \n",
            "                                        namespaces <n1> and <n2>\n",
            "\n",
            "  --csoaa arg                           One-against-all multiclass with <k> \n",
            "                                        costs\n",
            "\n",
            "  --cs_active arg                       Cost-sensitive active learning with <k>\n",
            "                                        costs\n",
            "\n",
            "  --multilabel_oaa arg                  One-against-all multilabel with <k> \n",
            "                                        labels\n",
            "\n",
            "  --classweight arg                     importance weight multiplier for class\n",
            "\n",
            "  --recall_tree arg                     Use online tree for multiclass\n",
            "\n",
            "  --log_multi arg                       Use online tree for multiclass\n",
            "\n",
            "  --ect arg                             Error correcting tournament with <k> \n",
            "                                        labels\n",
            "\n",
            "  --boosting arg                        Online boosting with <N> weak learners\n",
            "\n",
            "  --oaa arg                             One-against-all multiclass with <k> \n",
            "                                        labels\n",
            "\n",
            "  --top arg                             top k recommendation\n",
            "\n",
            "  --replay_m arg                        use experience replay at a specified \n",
            "                                        level [b=classification/regression, \n",
            "                                        m=multiclass, c=cost sensitive] with \n",
            "                                        specified buffer size\n",
            "\n",
            "  --binary                              report loss as binary classification on\n",
            "                                        -1,1\n",
            "\n",
            "  --bootstrap arg                       k-way bootstrap by online importance \n",
            "                                        resampling\n",
            "\n",
            "  --link arg (=identity)                Specify the link function: identity, \n",
            "                                        logistic, glf1 or poisson\n",
            "\n",
            "  --stage_poly                          use stagewise polynomial feature \n",
            "                                        learning\n",
            "\n",
            "  --lrqfa arg                           use low rank quadratic features with \n",
            "                                        field aware weights\n",
            "\n",
            "  --lrq arg                             use low rank quadratic features\n",
            "\n",
            "  --autolink arg                        create link function with polynomial d\n",
            "\n",
            "  --marginal arg                        substitute marginal label estimates for\n",
            "                                        ids\n",
            "\n",
            "  --new_mf arg                          rank for reduction-based matrix \n",
            "                                        factorization\n",
            "\n",
            "  --nn arg                              Sigmoidal feedforward network with <k> \n",
            "                                        hidden units\n",
            "\n",
            "confidence options:\n",
            "  --confidence_after_training           Confidence after training\n",
            "\n",
            "  --confidence                          Get confidence for binary predictions\n",
            "\n",
            "  --active_cover                        enable active learning with cover\n",
            "\n",
            "  --active                              enable active learning\n",
            "\n",
            "  --replay_b arg                        use experience replay at a specified \n",
            "                                        level [b=classification/regression, \n",
            "                                        m=multiclass, c=cost sensitive] with \n",
            "                                        specified buffer size\n",
            "\n",
            "  --baseline                            Learn an additive baseline (from \n",
            "                                        constant features) and a residual \n",
            "                                        separately in regression.\n",
            "\n",
            "  --OjaNewton                           Online Newton with Oja's Sketch\n",
            "\n",
            "  --bfgs                                use bfgs optimization\n",
            "\n",
            "  --conjugate_gradient                  use conjugate gradient based \n",
            "                                        optimization\n",
            "\n",
            "  --lda arg                             Run lda with <int> topics\n",
            "\n",
            "  --noop                                do no learning\n",
            "\n",
            "  --print                               print examples\n",
            "\n",
            "  --rank arg                            rank for matrix factorization.\n",
            "\n",
            "  --sendto arg                          send examples to <host>\n",
            "\n",
            "  --svrg                                Streaming Stochastic Variance Reduced \n",
            "                                        Gradient\n",
            "\n",
            "  --ftrl                                FTRL: Follow the Proximal Regularized \n",
            "                                        Leader\n",
            "\n",
            "  --pistol                              FTRL: Parameter-free Stochastic \n",
            "                                        Learning\n",
            "\n",
            "  --ksvm                                kernel svm\n",
            "\n",
            "Gradient Descent options:\n",
            "  --sgd                                 use regular stochastic gradient descent\n",
            "                                        update.\n",
            "  --adaptive                            use adaptive, individual learning \n",
            "                                        rates.\n",
            "  --adax                                use adaptive learning rates with x^2 \n",
            "                                        instead of g^2x^2\n",
            "  --invariant                           use safe/importance aware updates.\n",
            "  --normalized                          use per feature normalized updates\n",
            "  --sparse_l2 arg (=0)                  use per feature normalized updates\n",
            "\n",
            "Input options:\n",
            "  -d [ --data ] arg                     Example Set\n",
            "  --daemon                              persistent daemon mode on port 26542\n",
            "  --foreground                          in persistent daemon mode, do not run \n",
            "                                        in the background\n",
            "  --port arg                            port to listen on; use 0 to pick unused\n",
            "                                        port\n",
            "  --num_children arg                    number of children for persistent \n",
            "                                        daemon mode\n",
            "  --pid_file arg                        Write pid file in persistent daemon \n",
            "                                        mode\n",
            "  --port_file arg                       Write port used in persistent daemon \n",
            "                                        mode\n",
            "  -c [ --cache ]                        Use a cache.  The default is \n",
            "                                        <data>.cache\n",
            "  --cache_file arg                      The location(s) of cache_file.\n",
            "  --json                                Enable JSON parsing.\n",
            "  --dsjson                              Enable Decision Service JSON parsing.\n",
            "  -k [ --kill_cache ]                   do not reuse existing cache: create a \n",
            "                                        new one always\n",
            "  --compressed                          use gzip format whenever possible. If a\n",
            "                                        cache file is being created, this \n",
            "                                        option creates a compressed cache file.\n",
            "                                        A mixture of raw-text & compressed \n",
            "                                        inputs are supported with \n",
            "                                        autodetection.\n",
            "  --no_stdin                            do not default to reading from stdin\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WyBpJVo0Av8",
        "colab_type": "code",
        "outputId": "1f43850e-636f-4507-f2bf-5f7e79ff82b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip install vowpalwabbit\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vowpalwabbit in /usr/local/lib/python3.6/dist-packages (8.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-fz_Ks48dUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "all_documents = df['text']\n",
        "topic_encoder = LabelEncoder()\n",
        "all_targets_mult = topic_encoder.fit_transform(df['class']) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3VaDOOsCwf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrxXjmYW-eou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_documents, test_documents, train_labels_mult, test_labels_mult = \\\n",
        "    train_test_split(all_documents, all_targets_mult, random_state=7)\n",
        "\n",
        "def to_vw_format(document, label=None):\n",
        "    return str(label or '') + ' |text ' + ' '.join(re.findall('\\w{3,}', document.lower())) + '\\n'\n",
        "\n",
        "with open(os.path.join('/content/drive/My Drive/vw/train.vw'), 'w') as vw_train_data:\n",
        "    for text, target in zip(train_documents, train_labels_mult):\n",
        "        vw_train_data.write(to_vw_format(text, target))\n",
        "\n",
        "with open(os.path.join('/content/drive/My Drive/vw/test.vw'), 'w') as vw_test_data:\n",
        "    for text in test_documents:\n",
        "        vw_test_data.write(to_vw_format(text))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23xj58g9BB28",
        "colab_type": "code",
        "outputId": "a88b7910-f4b2-4c35-9995-6a557fcc57f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "# # Fitting a logistic regression for predicting the sentiment of a review\n",
        "# !vw -d movie_reviews_train.vw --loss_function logistic -f movie_reviews_model.vw\n",
        "%%time\n",
        "!vw --oaa 15 $\"/content/drive/My Drive/vw/train.vw\" -f $\"/content/drive/My Drive/vw/model_mult.vw\" \\\n",
        "--loss_function=hinge"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final_regressor = /content/drive/My Drive/vw/model_mult.vw\n",
            "Num weight bits = 18\n",
            "learning rate = 0.5\n",
            "initial_t = 0\n",
            "power_t = 0.5\n",
            "using no cache\n",
            "Reading datafile = /content/drive/My Drive/vw/train.vw\n",
            "num sources = 1\n",
            "average  since         example        example  current  current  current\n",
            "loss     last          counter         weight    label  predict features\n",
            "1.000000 1.000000            1            1.0       10        1        4\n",
            "1.000000 1.000000            2            2.0       11       10       14\n",
            "0.750000 0.500000            4            4.0       10       10        8\n",
            "0.750000 0.750000            8            8.0        4       10        3\n",
            "0.687500 0.625000           16           16.0       11       10        9\n",
            "0.625000 0.562500           32           32.0       10       15        4\n",
            "0.484375 0.343750           64           64.0       10       10        3\n",
            "0.445312 0.406250          128          128.0       10       10        4\n",
            "0.429688 0.414062          256          256.0       10       10        3\n",
            "0.396484 0.363281          512          512.0       10        7        2\n",
            "0.353516 0.310547         1024         1024.0       15       10        5\n",
            "0.325684 0.297852         2048         2048.0       11       11        2\n",
            "0.309814 0.293945         4096         4096.0        5       10        2\n",
            "\n",
            "finished run\n",
            "number of examples per pass = 7925\n",
            "passes used = 1\n",
            "weighted example sum = 7925.000000\n",
            "weighted label sum = 0.000000\n",
            "average loss = 0.297792\n",
            "total feature number = 30006\n",
            "CPU times: user 18.6 ms, sys: 8.89 ms, total: 27.5 ms\n",
            "Wall time: 3.02 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0PaM5BjFAps",
        "colab_type": "code",
        "outputId": "867bf626-2f54-448e-ecc7-64ff6d18b69e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "%%time\n",
        "!vw -i $\"/content/drive/My Drive/vw/model_mult.vw\" -t -d $\"/content/drive/My Drive/vw/test.vw\" \\\n",
        "-p $\"/content/drive/My Drive/vw/test_predictions_mult.txt\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "only testing\n",
            "predictions = /content/drive/My Drive/vw/test_predictions_mult.txt\n",
            "Num weight bits = 18\n",
            "learning rate = 0.5\n",
            "initial_t = 0\n",
            "power_t = 0.5\n",
            "using no cache\n",
            "Reading datafile = /content/drive/My Drive/vw/test.vw\n",
            "num sources = 1\n",
            "average  since         example        example  current  current  current\n",
            "loss     last          counter         weight    label  predict features\n",
            "    n.a.     n.a.            1            1.0  unknown        5        2\n",
            "    n.a.     n.a.            2            2.0  unknown        7        5\n",
            "    n.a.     n.a.            4            4.0  unknown       11        2\n",
            "    n.a.     n.a.            8            8.0  unknown       10        5\n",
            "    n.a.     n.a.           16           16.0  unknown       10        4\n",
            "    n.a.     n.a.           32           32.0  unknown       15        5\n",
            "    n.a.     n.a.           64           64.0  unknown        7        2\n",
            "    n.a.     n.a.          128          128.0  unknown       10        1\n",
            "    n.a.     n.a.          256          256.0  unknown       10        4\n",
            "    n.a.     n.a.          512          512.0  unknown       10        3\n",
            "    n.a.     n.a.         1024         1024.0  unknown       10        6\n",
            "    n.a.     n.a.         2048         2048.0  unknown       11        2\n",
            "\n",
            "finished run\n",
            "number of examples per pass = 2642\n",
            "passes used = 1\n",
            "weighted example sum = 2642.000000\n",
            "weighted label sum = 0.000000\n",
            "average loss = n.a.\n",
            "total feature number = 10110\n",
            "CPU times: user 17.2 ms, sys: 8.22 ms, total: 25.4 ms\n",
            "Wall time: 3.04 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BgyZdeuLMSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(os.path.join(\"/content/drive/My Drive/vw/test_predictions_mult.txt\")) as pred_file:\n",
        "    test_prediction_mult = [float(label) for label in pred_file.readlines()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBOkheZIM7-o",
        "colab_type": "code",
        "outputId": "3d5a1721-c26f-45c7-8c4b-e19304439389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(test_labels_mult, test_prediction_mult)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7369417108251325"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5kPuUUnQKJG",
        "colab_type": "code",
        "outputId": "7685b343-5bc9-4e98-d1e7-96a1c02e703b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "M = confusion_matrix(test_labels_mult, test_prediction_mult)\n",
        "for i in np.where(M[0,:] > 0)[0][1:]:\n",
        "    print(df['class'][i], M[0,i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statement 2\n",
            "Accept 1\n",
            "System 26\n",
            "System 3\n",
            "System 6\n",
            "Statement 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}